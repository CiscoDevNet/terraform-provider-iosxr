// Copyright Â© 2023 Cisco Systems, Inc. and its affiliates.
// All rights reserved.
//
// Licensed under the Mozilla Public License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//	https://mozilla.org/MPL/2.0/
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// SPDX-License-Identifier: MPL-2.0

// Code generated by "gen/generator.go"; DO NOT EDIT.

package provider

// Section below is generated&owned by "gen/generator.go". //template:begin imports
import (
	"context"
	"fmt"
	"regexp"
	"strings"

	"github.com/CiscoDevNet/terraform-provider-iosxr/internal/provider/helpers"
	"github.com/hashicorp/terraform-plugin-framework-validators/int64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/netascode/go-gnmi"
	"github.com/netascode/go-netconf"
)

// End of section. //template:end imports

// Section below is generated&owned by "gen/generator.go". //template:begin model

func NewFlowMonitorMapResource() resource.Resource {
	return &FlowMonitorMapResource{}
}

type FlowMonitorMapResource struct {
	data *IosxrProviderData
}

func (r *FlowMonitorMapResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_flow_monitor_map"
}

func (r *FlowMonitorMapResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		// This description is used by the documentation generator and the language server.
		MarkdownDescription: "This resource can manage the Flow Monitor Map configuration.",

		Attributes: map[string]schema.Attribute{
			"device": schema.StringAttribute{
				MarkdownDescription: "A device name from the provider configuration.",
				Optional:            true,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "The path of the object.",
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"name": schema.StringAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Monitor map name").String,
				Required:            true,
				Validators: []validator.String{
					stringvalidator.LengthBetween(1, 32),
					stringvalidator.RegexMatches(regexp.MustCompile(`[\w\-\.:,_@#%$\+=\| ;]+`), ""),
				},
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
			},
			"exporters": schema.ListNestedAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify flow exporter map name").String,
				Optional:            true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"name": schema.StringAttribute{
							MarkdownDescription: helpers.NewAttributeDescription("Specify flow exporter map name").String,
							Required:            true,
							Validators: []validator.String{
								stringvalidator.LengthBetween(1, 90),
								stringvalidator.RegexMatches(regexp.MustCompile(`[\w\-\.:,_@#%$\+=\| ;]+`), ""),
							},
						},
					},
				},
			},
			"option_outphysint": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("export output interfaces as physical interfaces").String,
				Optional:            true,
			},
			"option_filtered": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable filtering of records").String,
				Optional:            true,
			},
			"option_bgpattr": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("export bgp attributes AS_PATH and STD_COMMUNITY").String,
				Optional:            true,
			},
			"option_outbundlemember": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("export output physical interfaces of bundle interface").String,
				Optional:            true,
			},
			"record_ipv4": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv4 raw record format").String,
				Optional:            true,
			},
			"record_ipv4_destination": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv4 Destination Based NetFlow Accounting").String,
				Optional:            true,
			},
			"record_ipv4_destination_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv4 Destination Based NetFlow Accounting TOS").String,
				Optional:            true,
			},
			"record_ipv4_as": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Autonomous System based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_protocol_port": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Protocol-Port based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_prefix": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Prefix based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_source_prefix": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("source prefix based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_destination_prefix": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Destination prefix based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_as_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("AS-TOS based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_protocol_port_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Protocol, port and tos based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_prefix_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Prefix TOS based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_source_prefix_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Source, Prefix and TOS based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_destination_prefix_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Destination, prefix and tos based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_prefix_port": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Prefix port based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_bgp_nexthop_tos": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("BGP, nexthop and tos based aggregation").String,
				Optional:            true,
			},
			"record_ipv4_peer_as": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Record peer AS").String,
				Optional:            true,
			},
			"record_ipv4_gtp": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPV4 gtp record format").String,
				Optional:            true,
			},
			"record_ipv4_l2_l3": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv4 record with Layer2 details").String,
				Optional:            true,
			},
			"record_ipv4_extended": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv4 record with extended details").String,
				Optional:            true,
			},
			"record_ipv6": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv6 raw record format").String,
				Optional:            true,
			},
			"record_ipv6_destination": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv6 Destination Based NetFlow Accounting").String,
				Optional:            true,
			},
			"record_ipv6_peer_as": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Record peer AS").String,
				Optional:            true,
			},
			"record_ipv6_gtp": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPV6 gtp record format").String,
				Optional:            true,
			},
			"record_ipv6_srv6": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("SRv6 record format").String,
				Optional:            true,
			},
			"record_ipv6_l2_l3": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv6 record with Layer2 details").String,
				Optional:            true,
			},
			"record_ipv6_extended": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("IPv6 record with extended details").String,
				Optional:            true,
			},
			"record_mpls": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("MPLS record format").String,
				Optional:            true,
			},
			"record_mpls_ipv4_fields": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("MPLS with IPv4 fields format").String,
				Optional:            true,
			},
			"record_mpls_ipv6_fields": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("MPLS with IPv6 fields format").String,
				Optional:            true,
			},
			"record_mpls_ipv4_ipv6_fields": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("MPLS with IPv4 and IPv6 fields format").String,
				Optional:            true,
			},
			"record_mpls_labels": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Labels to be used for Hashing").AddIntegerRangeDescription(1, 6).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(1, 6),
				},
			},
			"record_map_t": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("map-t translation based Netflow").String,
				Optional:            true,
			},
			"record_sflow": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("sFlow based flow").String,
				Optional:            true,
			},
			"record_datalink_record": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Layer2 traffic based flow").String,
				Optional:            true,
			},
			"record_default_rtp": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Default RTP record format").String,
				Optional:            true,
			},
			"record_default_mdi": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Default MDI record format").String,
				Optional:            true,
			},
			"cache_entries": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify the number of entries in the flow cache").AddIntegerRangeDescription(4096, 1000000).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(4096, 1000000),
				},
			},
			"cache_timeout_active": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify the active flow timeout").AddIntegerRangeDescription(1, 604800).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(1, 604800),
				},
			},
			"cache_timeout_inactive": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify the inactive flow timeout").AddIntegerRangeDescription(0, 604800).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(0, 604800),
				},
			},
			"cache_timeout_update": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify the update timeout").AddIntegerRangeDescription(1, 604800).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(1, 604800),
				},
			},
			"cache_timeout_rate_limit": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Maximum number of entries to age each second").AddIntegerRangeDescription(1, 1000000).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(1, 1000000),
				},
			},
			"cache_permanent": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Disable removal of entries from flow cache").String,
				Optional:            true,
			},
			"cache_immediate": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Immediate removal of entries from flow cache").String,
				Optional:            true,
			},
			"hw_cache_timeout_inactive": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify the inactive timeout").AddIntegerRangeDescription(50, 1800).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(50, 1800),
				},
			},
			"sflow_options": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("submode to configure sFlow related options").String,
				Optional:            true,
			},
			"sflow_options_extended_router": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable extended-router flow data type").String,
				Optional:            true,
			},
			"sflow_options_extended_gateway": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable extended-gateway flow data type").String,
				Optional:            true,
			},
			"sflow_options_extended_ipv4_tunnel_egress": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable extended-ipv4-tunnel-egress flow data type").String,
				Optional:            true,
			},
			"sflow_options_extended_ipv6_tunnel_egress": schema.BoolAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable extended-ipv6-tunnel-egress flow data type").String,
				Optional:            true,
			},
			"sflow_options_if_counters_polling_interval": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Enable if-counters counter sampling rate").AddIntegerRangeDescription(5, 1800).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(5, 1800),
				},
			},
			"sflow_options_sample_header_size": schema.Int64Attribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify maximum sample-header size to be exported").AddIntegerRangeDescription(128, 343).String,
				Optional:            true,
				Validators: []validator.Int64{
					int64validator.Between(128, 343),
				},
			},
			"sflow_options_input_ifindex": schema.StringAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify ifindex related options").AddStringEnumDescription("physical").String,
				Optional:            true,
				Validators: []validator.String{
					stringvalidator.OneOf("physical"),
				},
			},
			"sflow_options_output_ifindex": schema.StringAttribute{
				MarkdownDescription: helpers.NewAttributeDescription("Specify ifindex related options").AddStringEnumDescription("physical").String,
				Optional:            true,
				Validators: []validator.String{
					stringvalidator.OneOf("physical"),
				},
			},
		},
	}
}

func (r *FlowMonitorMapResource) Configure(_ context.Context, req resource.ConfigureRequest, _ *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}

	r.data = req.ProviderData.(*IosxrProviderData)
}

// End of section. //template:end model

// Section below is generated&owned by "gen/generator.go". //template:begin create

func (r *FlowMonitorMapResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var plan FlowMonitorMap

	// Read plan
	diags := req.Plan.Get(ctx, &plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	device, ok := r.data.Devices[plan.Device.ValueString()]
	if !ok {
		resp.Diagnostics.AddAttributeError(path.Root("device"), "Invalid device", fmt.Sprintf("Device '%s' does not exist in provider configuration.", plan.Device.ValueString()))
		return
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Beginning Create", plan.getPath()))

	if device.Managed {
		if device.Protocol == "gnmi" {
			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("gNMI Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			// Ensure connection is closed when function exits (if reuse disabled)
			defer helpers.CloseGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection)

			var ops []gnmi.SetOperation

			// Create object
			body := plan.toBody(ctx)
			ops = append(ops, gnmi.Update(plan.getPath(), body))

			emptyLeafsDelete := plan.getEmptyLeafsDelete(ctx, nil)
			tflog.Debug(ctx, fmt.Sprintf("List of empty leafs to delete: %+v", emptyLeafsDelete))

			for _, i := range emptyLeafsDelete {
				ops = append(ops, gnmi.Delete(i))
			}

			_, err := device.GnmiClient.Set(ctx, ops)
			if err != nil {
				resp.Diagnostics.AddError("Unable to apply gNMI Set operation", err.Error())
				return
			}
		} else {
			// Serialize NETCONF operations when reuse disabled, or writes when reuse enabled
			locked := helpers.AcquireNetconfLock(&device.NetconfOpMutex, device.ReuseConnection, true)
			defer helpers.CloseNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection)
			if locked {
				defer device.NetconfOpMutex.Unlock()
			}

			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("NETCONF Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			bodyStr := plan.toBodyXML(ctx)
			tflog.Info(ctx, fmt.Sprintf("NETCONF CREATE: Initial body length: %d", len(bodyStr)))

			// Handle empty leafs (boolean false values) that need to be deleted
			emptyLeafsDelete := plan.getEmptyLeafsDelete(ctx, nil)
			tflog.Info(ctx, fmt.Sprintf("NETCONF CREATE: Empty leafs to delete: %+v", emptyLeafsDelete))

			if len(emptyLeafsDelete) > 0 {
				for _, deletePath := range emptyLeafsDelete {
					tflog.Info(ctx, fmt.Sprintf("NETCONF CREATE: Adding delete for path: %s", deletePath))
					deleteXml := helpers.RemoveFromXPathString(netconf.Body{}, deletePath)
					bodyStr += deleteXml
				}
				tflog.Info(ctx, fmt.Sprintf("NETCONF CREATE: Final body with deletes: %s", bodyStr))
			}

			if err := helpers.EditConfig(ctx, device.NetconfClient, bodyStr, true); err != nil {
				resp.Diagnostics.AddError("Client Error", err.Error())
				return
			}
		}
	}

	plan.Id = types.StringValue(plan.getPath())

	tflog.Debug(ctx, fmt.Sprintf("%s: Create finished successfully", plan.getPath()))

	diags = resp.State.Set(ctx, &plan)
	resp.Diagnostics.Append(diags...)

	helpers.SetFlagImporting(ctx, false, resp.Private, &resp.Diagnostics)
}

// End of section. //template:end create

// Section below is generated&owned by "gen/generator.go". //template:begin read

func (r *FlowMonitorMapResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var state FlowMonitorMap

	// Read state
	diags := req.State.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	device, ok := r.data.Devices[state.Device.ValueString()]
	if !ok {
		resp.Diagnostics.AddAttributeError(path.Root("device"), "Invalid device", fmt.Sprintf("Device '%s' does not exist in provider configuration.", state.Device.ValueString()))
		return
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Beginning Read", state.Id.ValueString()))

	if device.Managed {
		_ = diags // Avoid unused variable error
		if device.Protocol == "gnmi" {
			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("gNMI Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			defer helpers.CloseGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection)
			getResp, err := device.GnmiClient.Get(ctx, []string{state.Id.ValueString()})
			if err != nil {
				if strings.Contains(err.Error(), "Requested element(s) not found") {
					resp.State.RemoveResource(ctx)
					return
				} else {
					resp.Diagnostics.AddError("Unable to apply gNMI Get operation", err.Error())
					return
				}
			}

			// Defensive bounds checking for response structure
			if len(getResp.Notifications) == 0 {
				resp.Diagnostics.AddError("Invalid gNMI response",
					"Response contains no notifications")
				return
			}
			if len(getResp.Notifications[0].Update) == 0 {
				resp.Diagnostics.AddError("Invalid gNMI response",
					"Response notification contains no updates")
				return
			}

			// Use updateFromBody to preserve config values for fields not on device
			respBody := getResp.Notifications[0].Update[0].Val.GetJsonIetfVal()
			tflog.Debug(ctx, fmt.Sprintf("respBody : %s", respBody))
			state.updateFromBody(ctx, respBody)
		} else {
			// Serialize NETCONF operations when reuse disabled (concurrent reads allowed when reuse enabled)
			locked := helpers.AcquireNetconfLock(&device.NetconfOpMutex, device.ReuseConnection, false)
			defer helpers.CloseNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection)
			if locked {
				defer device.NetconfOpMutex.Unlock()
			}

			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("NETCONF Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			filter := helpers.GetSubtreeFilter(state.getXPath())
			res, err := device.NetconfClient.GetConfig(ctx, "running", filter)
			if err != nil {
				resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Failed to retrieve object (%s), got error: %s", state.getPath(), err))
				return
			}

			tflog.Debug(ctx, fmt.Sprintf("NETCONF GetConfig response for %s: isEmpty=%v, isListPath=%v",
				state.getXPath(), helpers.IsGetConfigResponseEmpty(&res), helpers.IsListPath(state.getXPath())))

			if helpers.IsGetConfigResponseEmpty(&res) && helpers.IsListPath(state.getXPath()) {
				// NETCONF returned empty response for a list resource
				// This can happen on IOS-XR for certain resources even when they exist
				// Instead of removing the resource, log a warning and preserve the current state
				// This matches gNMI behavior where we keep the resource if we can't read it
				tflog.Warn(ctx, fmt.Sprintf("%s: NETCONF returned empty response for list path, preserving state as-is", state.Id.ValueString()))
				// Don't call updateFromBodyXML - keep state unchanged
			} else {
				// Use updateFromBodyXML to preserve config values for fields not on device
				state.updateFromBodyXML(ctx, res.Res)
			}
		}
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Read finished successfully", state.Id.ValueString()))

	diags = resp.State.Set(ctx, &state)
	resp.Diagnostics.Append(diags...)

	helpers.SetFlagImporting(ctx, false, resp.Private, &resp.Diagnostics)
}

// End of section. //template:end read

// Section below is generated&owned by "gen/generator.go". //template:begin update

func (r *FlowMonitorMapResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var plan, state FlowMonitorMap

	// Read plan
	diags := req.Plan.Get(ctx, &plan)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	// Read state
	diags = req.State.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	device, ok := r.data.Devices[plan.Device.ValueString()]
	if !ok {
		resp.Diagnostics.AddAttributeError(path.Root("device"), "Invalid device", fmt.Sprintf("Device '%s' does not exist in provider configuration.", plan.Device.ValueString()))
		return
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Beginning Update", plan.Id.ValueString()))

	if device.Managed {
		if device.Protocol == "gnmi" {
			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("gNMI Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			// Ensure connection is closed when function exits (if reuse disabled)
			defer helpers.CloseGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection)

			var ops []gnmi.SetOperation

			// Update object
			body := plan.toBody(ctx)
			ops = append(ops, gnmi.Update(plan.getPath(), body))

			deletedListItems := plan.getDeletedItems(ctx, state)
			tflog.Debug(ctx, fmt.Sprintf("Removed items to delete: %+v", deletedListItems))

			for _, i := range deletedListItems {
				ops = append(ops, gnmi.Delete(i))
			}

			emptyLeafsDelete := plan.getEmptyLeafsDelete(ctx, &state)
			tflog.Debug(ctx, fmt.Sprintf("List of empty leafs to delete: %+v", emptyLeafsDelete))

			for _, i := range emptyLeafsDelete {
				ops = append(ops, gnmi.Delete(i))
			}

			_, err := device.GnmiClient.Set(ctx, ops)
			if err != nil {
				resp.Diagnostics.AddError("Unable to apply gNMI Set operation", err.Error())
				return
			}
		} else {
			// Serialize NETCONF operations when reuse disabled, or writes when reuse enabled
			locked := helpers.AcquireNetconfLock(&device.NetconfOpMutex, device.ReuseConnection, true)
			defer helpers.CloseNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection)
			if locked {
				defer device.NetconfOpMutex.Unlock()
			}

			// Ensure connection is healthy (reconnect if stale)
			if err := helpers.EnsureNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection); err != nil {
				resp.Diagnostics.AddError("NETCONF Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
				return
			}

			body := plan.toBodyXML(ctx)
			deleteBody := plan.addDeletedItemsXML(ctx, state, "")

			// Also handle empty leaf deletes (for boolean false values)
			emptyLeafsDelete := plan.getEmptyLeafsDelete(ctx, &state)
			tflog.Debug(ctx, fmt.Sprintf("List of empty leafs to delete: %+v", emptyLeafsDelete))
			for _, deletePath := range emptyLeafsDelete {
				deleteBody += helpers.RemoveFromXPathString(netconf.Body{}, deletePath)
			}

			// Combine update and delete operations into a single transaction
			combinedBody := body + deleteBody
			if err := helpers.EditConfig(ctx, device.NetconfClient, combinedBody, true); err != nil {
				resp.Diagnostics.AddError("Client Error", err.Error())
				return
			}
		}
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Update finished successfully", plan.Id.ValueString()))

	diags = resp.State.Set(ctx, &plan)
	resp.Diagnostics.Append(diags...)
}

// End of section. //template:end update

// Section below is generated&owned by "gen/generator.go". //template:begin delete

func (r *FlowMonitorMapResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var state FlowMonitorMap

	// Read state
	diags := req.State.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	device, ok := r.data.Devices[state.Device.ValueString()]
	if !ok {
		resp.Diagnostics.AddAttributeError(path.Root("device"), "Invalid device", fmt.Sprintf("Device '%s' does not exist in provider configuration.", state.Device.ValueString()))
		return
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Beginning Delete", state.Id.ValueString()))

	if device.Managed {
		deleteMode := "all"

		if deleteMode == "all" {
			if device.Protocol == "gnmi" {
				// Ensure connection is healthy (reconnect if stale)
				if err := helpers.EnsureGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection); err != nil {
					resp.Diagnostics.AddError("gNMI Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
					return
				}

				// Ensure connection is closed when function exits (if reuse disabled)
				defer helpers.CloseGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection)

				var ops []gnmi.SetOperation
				ops = append(ops, gnmi.Delete(state.Id.ValueString()))

				_, err := device.GnmiClient.Set(ctx, ops)
				if err != nil {
					resp.Diagnostics.AddError("Unable to apply gNMI Set operation", err.Error())
					return
				}
			} else {
				// NETCONF - Serialize write operations
				locked := helpers.AcquireNetconfLock(&device.NetconfOpMutex, device.ReuseConnection, true)
				defer helpers.CloseNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection)
				if locked {
					defer device.NetconfOpMutex.Unlock()
				}

				// Ensure connection is healthy (reconnect if stale)
				if err := helpers.EnsureNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection); err != nil {
					resp.Diagnostics.AddError("NETCONF Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
					return
				}

				body := netconf.Body{}
				xpath := state.getXPath()
				// RemoveFromXPathString returns raw XML string for delete operations
				xmlStr := helpers.RemoveFromXPathString(body, xpath)

				if err := helpers.EditConfig(ctx, device.NetconfClient, xmlStr, true); err != nil {
					// Ignore data-missing errors as the resource may already be deleted
					if !strings.Contains(err.Error(), "data-missing") {
						resp.Diagnostics.AddError("Client Error", err.Error())
						return
					}
					tflog.Debug(ctx, fmt.Sprintf("%s: Resource already deleted or does not exist", state.Id.ValueString()))
				}
			}
		} else {
			if device.Protocol == "gnmi" {
				// Ensure connection is healthy (reconnect if stale)
				if err := helpers.EnsureGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection); err != nil {
					resp.Diagnostics.AddError("gNMI Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
					return
				}

				// Ensure connection is closed when function exits (if reuse disabled)
				defer helpers.CloseGnmiConnection(ctx, device.GnmiClient, device.ReuseConnection)

				var ops []gnmi.SetOperation
				deletePaths := state.getDeletePaths(ctx)
				tflog.Debug(ctx, fmt.Sprintf("Paths to delete: %+v", deletePaths))

				for _, i := range deletePaths {
					ops = append(ops, gnmi.Delete(i))
				}

				if len(ops) > 0 {
					_, err := device.GnmiClient.Set(ctx, ops)
					if err != nil {
						resp.Diagnostics.AddError("Unable to apply gNMI Set operation", err.Error())
						return
					}
				}
			} else {
				// NETCONF - Serialize write operations
				locked := helpers.AcquireNetconfLock(&device.NetconfOpMutex, device.ReuseConnection, true)
				defer helpers.CloseNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection)
				if locked {
					defer device.NetconfOpMutex.Unlock()
				}

				// Ensure connection is healthy (reconnect if stale)
				if err := helpers.EnsureNetconfConnection(ctx, device.NetconfClient, device.ReuseConnection); err != nil {
					resp.Diagnostics.AddError("NETCONF Connection Error", fmt.Sprintf("Failed to ensure connection: %s", err))
					return
				}

				body := state.addDeletePathsXML(ctx, "")

				if err := helpers.EditConfig(ctx, device.NetconfClient, body, true); err != nil {
					// Ignore data-missing errors as the attributes may already be deleted
					if !strings.Contains(err.Error(), "data-missing") {
						resp.Diagnostics.AddError("Client Error", err.Error())
						return
					}
					tflog.Debug(ctx, fmt.Sprintf("%s: Attributes already deleted or do not exist", state.Id.ValueString()))
				}
			}
		}
	}

	tflog.Debug(ctx, fmt.Sprintf("%s: Delete finished successfully", state.Id.ValueString()))

	resp.State.RemoveResource(ctx)
}

// End of section. //template:end delete

// Section below is generated&owned by "gen/generator.go". //template:begin import

func (r *FlowMonitorMapResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	idParts := strings.Split(req.ID, ",")
	idParts = helpers.RemoveEmptyStrings(idParts)

	if len(idParts) != 1 && len(idParts) != 2 {
		expectedIdentifier := "Expected import identifier with format: '<name>'"
		expectedIdentifier += " or '<name>,<device>'"
		resp.Diagnostics.AddError(
			"Unexpected Import Identifier",
			fmt.Sprintf("%s. Got: %q", expectedIdentifier, req.ID),
		)
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("name"), idParts[0])...)
	if len(idParts) == 2 {
		resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("device"), idParts[len(idParts)-1])...)
	}

	// construct path for 'id' attribute
	var state FlowMonitorMap
	diags := resp.State.Get(ctx, &state)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), state.getPath())...)

	helpers.SetFlagImporting(ctx, true, resp.Private, &resp.Diagnostics)
}

// End of section. //template:end import
